\section{Problems before 4.19.2020}

Just in case you don't have the access to the book while you are at home, I attached the two book in pdf file in the attachments too.

\subsection{Max of linear functionals = convex functional?}
When Dr. Tao was introducing Courant-Fisher minimax theorem(\textit{Theorem 1.3.2},Page 42), he said 

\textit{The $i^th$ eigenvalue functional $A\to \lambda_i(A)$ is not a linear funcional, nor convex or concave functionals. (except in dimension 1). But it's the next best thing, a minimax expression of linear functionals.}

Then he added in the footnote,

\textit{A convex functional is the same thing as a max of linear functionals, while a concave functional is the same thing as a min of linear functionals.}

I don't understand why they are the "same thing". Or could you please explain what are those linear functionals that after taking maximum can become a "same thing" to our convex functional. 

% \section{Does the supremum harm convexity?}

% The last question kind of remind me of one question I encounter doing an exercise in Dr.Vershynin's book.

% There's a lemma that one needs for symmetrization technique, and later used in empirical process of course.
% \begin{lemma}[6.1.2 in Dr.Vershynin's book]
%     Let $Y$ and $Z$ be independent random variables such that $\E Z=0$. Then, for every convex function $F$, one has
%     \begin{equation*}
%         \E F(Y) \leq \E F(Y+Z)
%     \end{equation*}
% \end{lemma}

% In particularly we care about the case when $F$ is a norm. 

% But in empirical process(\textit{specifically Exercise 8.3.24}) if we want to apply this lemma to use symmetrization technique, we have to check that the convexity of a function(or functional) in the form of
% \begin{equation*}
%     \sup_{f\in \mathcal{F}}|\sum_{i=1}^nh_f(X_i)|
% \end{equation*}

% where $h_f(X_i)=\frac{1}{n}(f(X_i)-\E f(X))$, $\mathcal F$ is a class of functions on a probability space $(\Omega,\Sigma,\mu)$, and $X_1,\dots,X_n$ be random points in $\Omega$ distributed according to the law $\mu$.

% $h_f$ is obvious mean zero. But how can I check the convexity here? It's obvious that the absolute value is convex but how does this supremum affects convexity? 

% Overall, I think so far the main obstacle in my reading is to work with complex matrices and asymptotic notation.